---
title: "Compilation Report | Corpus des Deutschen Bundesrechts (C-DBR)"
author: Seán Fobbe
geometry: margin=3cm
fontsize: 11pt
papersize: a4
output:
  pdf_document:
    toc: true
    toc_depth: 3
    number_sections: true
    pandoc_args: --listings
    includes:
      in_header: tex/Preamble_DE.tex
      before_body: [temp/Definitions.tex, tex/Titlepage_Compilation.tex]
bibliography: temp/packages.bib
nocite: '@*'
---



```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = TRUE,
                      message = TRUE,
                      collapse = TRUE,
                      comment = "#>")
```




```{r, results = "asis", echo = FALSE}
cat(readLines("README.md")[-1],
    sep = "\n")
```



# Packages laden


```{r}

library(targets)
library(tarchetypes)
library(RcppTOML)
library(future)
library(data.table)
library(quanteda)
library(knitr)
library(kableExtra)
library(igraph)
library(ggraph)

tar_unscript()
```



# Vorbereitung

## Definitionen

```{r}

## Datum
datestamp <- Sys.Date()
print(datestamp)

## Datum und Uhrzeit (Beginn)
begin.script <- Sys.time()

## Konfiguration
config <- RcppTOML::parseTOML("config.toml")
print(config)


# Analyse-Ordner
dir.analysis <- paste0(getwd(),
                       "/analysis")


```


## Aufräumen

Löscht Dateien im Output-Ordner, die nicht vom heutigen Tag sind.


```{r}

unlink(grep(datestamp,
            list.files("output",
                       full.names = TRUE),
            invert = TRUE,
            value = TRUE))


```



## Ordner erstellen

```{r}

#unlink("output", recursive = TRUE)
dir.create("files", showWarnings = FALSE)
dir.create("output", showWarnings = FALSE)
dir.create("temp", showWarnings = FALSE)

dir.create(dir.analysis, showWarnings = FALSE)

```



## Vollzitate statistischer Software schreiben

```{r}
knitr::write_bib(renv::dependencies()$Package,
                 "temp/packages.bib")
```




# Globale Variablen


## Packages definieren

```{targets global-packages, tar_globals = TRUE}

tar_option_set(packages = c("tarchetypes",
                            "RcppTOML",     # TOML-Dateien lesen und schreiben
							"testthat",     # Unit Tests
                            "fs",           # Verbessertes File Handling
                            "zip",          # Verbessertes ZIP Handling
                            "mgsub",        # Vektorisiertes Gsub
                            "httr",         # HTTP-Werkzeuge
							"xml2",         # XML-Extraktion
                            "rvest",        # HTML-Extraktion
                            "knitr",        # Professionelles Reporting
                            "kableExtra",   # Verbesserte Kable Tabellen
                            "pdftools",     # Verarbeitung von PDF-Dateien
                            "ggplot2",      # Datenvisualisierung
							"ggraph",       # Visualisierung von Graphen
							"igraph",       # Analyse von Graphen
                            "scales",       # Skalierung von Diagrammen
                            "data.table",   # Fortgeschrittene Datenverarbeitung
                            "readtext",     # TXT-Dateien einlesen
                            "quanteda",     # Computerlinguistik
                            "future",       # Parallelisierung
                            "future.apply"))# Funktionen für Future

tar_option_set(workspace_on_error = TRUE) # Save Workspace on Error
tar_option_set(format = "qs")

```


## Konfiguration


```{targets global-config, tar_globals = TRUE}

datestamp <- Sys.Date()

config <- RcppTOML::parseTOML("config.toml")

dir.analysis <- paste0(getwd(),
                       "/analysis")

## Caption for diagrams
caption <- paste("Fobbe | DOI:",
                 config$doi$data$version)


## Prefix for figure titles
prefix.figuretitle <- paste(config$project$shortname,
                            "| Version",
                            datestamp)

## File prefix
prefix.files <- paste0(config$project$shortname,
                       "_",
                       datestamp)


if (config$cores$max == TRUE){
    fullCores <- future::availableCores()
}


if (config$cores$max == FALSE){
    fullCores <- as.integer(config$cores$number)
}

```




## Funktionen definieren

```{targets global-functions, tar_globals = TRUE}

lapply(list.files("functions", pattern = "\\.R$", full.names = TRUE), source)

```






## ZIP-Datei für Source definieren

```{targets global-sourcefiles, tar_globals = TRUE}

files.source.raw <-  c(list.files(pattern = "\\.R$|\\.toml$|\\.md$|\\.Rmd$"),
					   "reports",
                       "data",
                       "functions",
                       "tex",
                       "gpg",
                       "buttons",
                       list.files(pattern = "renv\\.lock|\\.Rprofile",
                                  all.files = TRUE),
                       list.files("renv",
                                  pattern = "activate\\.R",
                                  full.names = TRUE))

```






# Pipeline: Konstruktion




## File Tracking Targets

Mit diesem Abschnitt der Pipeline werden Input-Dateien getrackt und eingelesen. Mit der Option \enquote{format = "file"} werden für Input-Dateien Prüfsummen berechnet. Falls sich diese verändern werden alle von ihnen abhängigen Pipeline-Schritte als veraltet markiert und neu berechnet.




### Source Code


Dies sind alle Dateien, die den Source Code für den Datensatz bereitstellen.

```{targets tar.file.source}
tar_target(files.source,
           files.source.raw,
           format = "file")

```


### Changelog

```{targets tar.file.changelog}
tar_target(changelog,
           "CHANGELOG.md",
           format = "file")
```



## Download Targets



### URLs für XML-Archive

```{targets tar.download.xmlurl}

tar_target(url.xml,
           f.links_xml())

```


### Tabelle der Dateinamen erstellen

```{targets tar.download.filenames}

tar_target(dt.filenames,
           f.html_landing_pages(url.xml,
                                multicore = config$parallel$htmlLandingPages,
                                cores = fullCores))

```

### Download Tabelle erstellen


```{targets tar.download.table}

tar_target(dt.download,
           f.download_table_make(dt.filenames = dt.filenames,
                                 url.xml = url.xml,
                                 xml.toc = "https://www.gesetze-im-internet.de/gii-toc.xml"))

```

### Konkordanzabelle erstellen


```{targets tar.download.conc}

tar_target(dt.conctable,
           f.conctable(dt.download = dt.download))

```



### Document Type Definition (DTD) herunterladen



```{targets tar.download.dtd}

tar_target(file.dtd,
           f.download("https://www.gesetze-im-internet.de/dtd/1.01/gii-norm.dtd",
                      paste0(prefix.files,
                             "_DE_XML_Document-Type-Definition_v1-01.dtd"),
                      dir = "output",
                      clean = FALSE),
           format = "file")

```



### XML (ZIP)-Archive herunterladen


```{targets tar.download.xmlzip}
tar_target(files.xmlzip,
                f.download(url = dt.download$url.xml,
                           filename = dt.download$title.xml,
                           dir = "files/xml_zip",
						   clean = TRUE,
						   multicore = config$parallel$downloadXML,
						   cores = fullCores,
                           sleep.min = 0,
                           sleep.max = 0,
                           retries = 3,
                           retry.sleep.min = 1,
                           retry.sleep.max = 2,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```



### PDF-Dateien herunterladen


```{targets tar.download.pdf}
tar_target(files.pdf,
                f.download(url = dt.download$url.pdf,
                           filename = dt.download$title.pdf,
                           dir = "files/pdf",
						   clean = TRUE,
						   multicore = config$parallel$downloadPDF,
						   cores = fullCores,
                           sleep.min = 0,
                           sleep.max = 0,
                           retries = 3,
                           retry.sleep.min = 1,
                           retry.sleep.max = 2,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```


### EPUB-Dateien herunterladen


```{targets tar.download.epub}
tar_target(files.epub,
                f.download(url = dt.download$url.epub,
                           filename = dt.download$title.epub,
                           dir = "files/epub",
						   clean = TRUE,
						   multicore = config$parallel$downloadEPUB,
						   cores = fullCores,
                           sleep.min = 0,
                           sleep.max = 0,
                           retries = 3,
                           retry.sleep.min = 1,
                           retry.sleep.max = 2,
                           timeout = config$download$timeout,
                           debug.toggle = FALSE,
                           debug.files = 500),
                format = "file")

```



## Convert Targets


### Entpacken


```{targets tar.convert.unzip}
tar_target(files.xml.all,
           f.tar_unzip(zipfiles = files.xmlzip,
                       exdir = "files/xml"),
           format = "file")

```

### XML-Dateien bestimmen


```{targets tar.convert.xmlfiles}
tar_target(files.xml,
           files.xml.all[grepl("\\.xml$", files.xml.all)],
           format = "file")

```



### PDF zu TXT konvertieren


```{targets tar.convert.txt}

tar_target(files.txt, 
           f.tar_pdf_extract(x = files.pdf, 
                             outputdir = "files/txt", 
                             multicore = config$parallel$extractPDF, 
                             cores = fullCores), 
           format = "file") 

```




## Parse Targets


### Datensatz erstellen: Einzelnormen

```{targets tar.parse.normen}
tar_target(dt.normen,
           f.dt.einzelnormen(file.xml = files.xml,
                  multicore = config$parallel$parseEinzelnormen,
                  cores = fullCores))

```

### Datensatz erstellen: Rechtsakte (mit Text)

```{targets tar.parse.rechtsakte}
tar_target(dt.rechtsakte,
           f.dt.rechtsakte(dt.normen))

```


### Datensatz erstellen: XML-Metadaten

 Diese Datei unterscheidet sich von der Variante der "Rechtsakte (Metadaten)", weil sie auch Rechtsakte enthält, die ohne Text veröffentlicht wurden. Die Differenz betrifft etwa 1000 Rechtsakte, ist also erheblich.


```{targets tar.parse.xmlmeta}
tar_target(dt.meta,
           f.dt.meta(file.xml = files.xml,
                  multicore = config$parallel$parseMeta,
                  cores = fullCores))

```


### Netzwerk-Analyse

```{targets tar.parse.networks}
tar_target(files.network,
           f.network.analysis(files.xml = files.xml,
                              prefix.figuretitle = prefix.figuretitle,
                              caption = caption,
                              dir.out = "netzwerke",
                              multicore = config$parallel$parseNetworks,
                              cores = fullCores),
           format = "file")

```





## Enhance Targets



### Variablen erstellen: \enquote{zeichen, token, typen, saetze}

Berechnung klassischer linguistischer Kennzahlen.



```{targets tar.enhance.lingstats.normen}
tar_target(var_lingstats.normen,
                f.lingstats(dt.normen,
                            multicore = config$parallel$lingsummarize,
                            cores = fullCores,
                            germanvars = TRUE))
```



```{targets tar.enhance.lingstats.rechtsakte}
tar_target(var_lingstats.rechtsakte,
                f.lingstats(dt.rechtsakte,
                            multicore = config$parallel$lingsummarize,
                            cores = fullCores,
                            germanvars = TRUE))
```




### Finale Datensätze erstellen


```{targets tar.enhance.finalize.normen}
tar_target(dt.normen.final,
           cbind(dt.normen,
                 var_lingstats.normen))
```


```{targets tar.enhance.finalize.rechtsakte}
tar_target(dt.rechtsakte.final,
           cbind(dt.rechtsakte,
                 var_lingstats.rechtsakte))
```


### Varianten erstellen: Nur Metadaten


```{targets tar.enhance.finalize.normen.meta}
tar_target(dt.normen.meta,
           dt.normen[, !"text"])
```



```{targets tar.enhance.finalize.rechtsakte.meta}
tar_target(dt.rechtsakte.meta,
           dt.rechtsakte[, !"text"])
```





## Write Targets

Dieser Abschnitt der Pipeline schreibt den Datensatz und alle Hash-Prüfsummen auf die Festplatte.


```{targets tar.write}

values <- tibble::tibble(
                      name = c("download",
                               "conctable",
                               "normen",
                               "normen_meta",
                               "rechtsakte",
                               "rechtsakte_meta",
                               "xml_meta"),
                      input = c(quote(dt.download),
                                quote(dt.conctable),
                                quote(dt.normen.final),
                                quote(dt.rechtsakte.final),
                                quote(dt.normen.meta),
                                quote(dt.rechtsakte.meta),
                                quote(dt.meta)
                                ),
                      filename = paste0(prefix.files,
                                        c("_02_Download-Tabelle",
                                          "_DE_Alle-Rechtsakte-Verzeichnis",
                                          "_DE_CSV_Einzelnormen_Datensatz",
                                          "_DE_CSV_Einzelnormen_Metadaten",
                                          "_DE_CSV_Rechtsakte_Datensatz",
                                          "_DE_CSV_Rechtsakte_Metadaten",
                                          "_DE_CSV_Metadaten-XML_Datensatz"),
                                        ".csv"),
                      dir = c(dir.analysis,
                              rep("output", 6))
                  )




csv.all <- tarchetypes::tar_map(unlist = FALSE,
                                values = values,
                                names = name,
                                tar_target(csv,
                                           f.tar_fwrite(x = input,
                                                        filename = file.path(dir,
                                                                             filename)),
                                           format = "file")
                                )

```





<!-- ### CSV schreiben: Download-Tabelle -->


<!-- ```{targets tar.write.download} -->
<!-- tar_target(csv.download, -->
<!--            f.tar_fwrite(x = dt.download, -->
<!--                         filename = file.path(dir.analysis, -->
<!--                                              paste0(prefix.files, -->
<!--                                                     "_02_Download-Tabelle.csv")) -->
<!--                         ) -->
<!--            ) -->
<!-- ``` -->


<!-- ### CSV schreiben: Konkordanztabelle -->


<!-- ```{targets tar.write.conc} -->
<!-- tar_target(csv.conctable, -->
<!--            f.tar_fwrite(x = dt.conctable, -->
<!--                         filename = file.path("output", -->
<!--                                              paste0(prefix.files, -->
<!--                                                     "_DE_Alle-Rechtsakte-Verzeichnis.csv")) -->
<!--                         ) -->
<!--            ) -->
<!-- ``` -->



<!-- ### CSV schreiben: Einzelnormen -->

<!-- ```{targets tar.write.normen} -->
<!-- tar_target(csv.normen, -->
<!--            f.tar_fwrite(x = dt.normen, -->
<!--                         filename = file.path("output", -->
<!--                                              paste0(prefix.files, -->
<!--                                                     "_DE_CSV_Einzelnormen_Datensatz.csv")) -->
<!--                         ) -->
<!--            ) -->
<!-- ``` -->


<!-- ### CSV schreiben: Rechtsakte (mit Text) -->

<!-- ```{targets tar.write.rechtsakte} -->
<!-- tar_target(csv.rechtsakte, -->
<!--            f.tar_fwrite(x = dt.rechtsakte, -->
<!--                         filename = file.path("output", -->
<!--                                              paste0(prefix.files, -->
<!--                                                     "_DE_CSV_Rechtsakte_Datensatz.csv")) -->
<!--                         ) -->
<!--            ) -->
<!-- ``` -->




<!-- ### CSV schreiben: XML-Metadaten -->

<!-- ```{targets tar.write.xmlmeta} -->
<!-- tar_target(csv.meta, -->
<!--            f.tar_fwrite(x = dt.meta, -->
<!--                         filename = file.path("output", -->
<!--                                              paste0(prefix.files, -->
<!--                                                     "_DE_CSV_Metadaten-XML.csv")) -->
<!--                         ) -->
<!--            ) -->
<!-- ``` -->







## Report Targets

Dieser Abschnitt der Pipeline erstellt die finalen Berichte (Codebook und Robustness Checks).



### LaTeX-Definitionen schreiben

Um Variablen aus der Pipeline in die LaTeX-Kompilierung einzuführen, müssen diese als .tex-Datei auf die Festplatte geschrieben werden.

```{targets tar.report.defs}
tar_target(latexdefs,
                f.latexdefs(config,
                            dir = "temp",
                            version = datestamp),
	       format = "file")

```

### Zusammenfassungen linguistischer Kennwerte berechnen

```{targets tar.report.lingstatsummary.normen}
tar_target(lingstats.summary.normen,
                f.lingstats_summary(dt.normen.final,
                                    germanvars = TRUE))

```

```{targets tar.report.lingstatsummary.rechtsakte}
tar_target(lingstats.summary.rechtsakte,
                f.lingstats_summary(dt.rechtsakte.final,
                                    germanvars = TRUE))

```





### Report erstellen: Robustness Checks

```{targets tar.report.robustness}
tarchetypes::tar_render(report.robustness,
                        file.path("reports",
                                  "RobustnessChecks.Rmd"),
                        output_file = file.path("../output",
                                                paste0(config$project$shortname,
                                                       "_",
                                                       datestamp,
                                                       "_RobustnessChecks.pdf")))

```



### Report erstellen: Codebook



```{targets tar.report.codebook}
tarchetypes::tar_render(report.codebook,
                        file.path("reports",
                                  "Codebook.Rmd"),
                        output_file = file.path("../output",
                                                paste0(config$project$shortname,
                                                       "_",
                                                       datestamp,
                                                       "_Codebook.pdf")))

```






## ZIP Targets

Diese Abschnitt der Pipeline erstellt ZIP-Archive für alle zentralen Rechenergebnisse und speichert diese im Ordner \enquote{output}.


### ZIP erstellen: Map


<!-- ```{targets tar.zip.source} -->
<!-- tar_target(zip.source, -->
<!--                 f.tar_zip(files.source, -->
<!--                               filename = paste0(prefix.files, -->
<!--                                                 "_Source_Code.zip"), -->
<!--                               dir = "output", -->
<!--                               mode = "mirror"), -->
<!--                 format = "file") -->
<!-- ``` -->




<!-- ### ZIP erstellen: XML -->


<!-- ```{targets tar.zip.xml} -->
<!-- tar_target(zip.xml, -->
<!--                 f.tar_zip(files.xml, -->
<!--                               filename = paste0(prefix.files, -->
<!--                                                 "_DE_XML_Datensatz.zip"), -->
<!--                               dir = "output", -->
<!--                               mode = "mirror"), -->
<!--                 format = "file") -->
<!-- ``` -->




<!-- ```{targets tar.zip.attachments} -->
<!-- tar_target(zip.xml, -->
<!--                 f.tar_zip(files.xml, -->
<!--                               filename = paste0(prefix.files, -->
<!--                                                 "_DE_XML_Datensatz.zip"), -->
<!--                               dir = "output", -->
<!--                               mode = "mirror"), -->
<!--                 format = "file") -->
<!-- ``` -->





```{targets tar.zip}

values <- tibble::tibble(
                      name = c("source",
                               "networks",
                               "pdf",
                               "epub",
                               "xml",
                               "attachments",
                               "einzelnormen_",
                               "einzelnormen_meta",
                               "rechtsakte",
                               "rechtsakte_meta",
                               "xml_meta"),
                      input = c(quote(files.source),
                                quote(files.network),
                                quote(files.pdf),
                                quote(files.epub),
                                quote(files.xml),
                                quote(setdiff(files.xml.all, files.xml)),
                                quote(csv_normen),
                                quote(csv_normen_meta),
                                quote(csv_rechtsakte),
                                quote(csv_rechtsakte_meta),
                                quote(csv_xml_meta)),
                      filename = paste0(prefix.files,
                                        c("_Source_Code",
                                          "_DE_Netzwerke",
                                          "_DE_PDF_Datensatz",
                                          "_DE_EPUB_Datensatz",
                                          "_DE_XML_Datensatz",
                                          "_DE_XML_Anlagen",
                                          "_DE_CSV_Einzelnormen_Datensatz",
                                          "_DE_CSV_Einzelnormen_Metadaten",
                                          "_DE_CSV_Rechtsakte_Datensatz",
                                          "_DE_CSV_Rechtsakte_Metadaten",
                                          "_DE_CSV_Metadaten-XML"),
                                        ".zip"),
                      mode = c(rep("mirror", 2),
                               rep("cherry-pick", 9))
                  )




zip.all <- tarchetypes::tar_map(unlist = FALSE,
                                values = values,
                                names = name,
                                tar_target(zip,
                                           f.tar_zip(x = input,
                                                     filename = filename,
                                                     dir = "output",
                                                     mode = mode),
                                           format = "file")
                                )



```










# Pipeline: Kompilierung



## Durchführen der Kompilierung


```{r pipeline-run, results = "hide"}
tar_make()
```



## Visualisierung

```{r, pipeline-graph, fig.width = 10, fig.height = 14}

edgelist <- tar_network(targets_only = TRUE)$edges
setDT(edgelist)

g  <- igraph::graph.data.frame(edgelist,
                               directed = TRUE)


ggraph(g,
       'sugiyama') +
    geom_edge_diagonal(colour = "grey70")+
    geom_node_point(size = 2)+
    geom_node_text(aes(label = name),
                   size = 2,
                   repel = TRUE)+
    theme_void()

```
                       



# Pipeline: Analyse


## Gesamte Liste

Die vollständige Liste aller Targets, inklusive ihres Types und ihrer Größe. Targets die auf Dateien verweisen (z.B. alle PDF-Dateien) geben die Gesamtgröße der Dateien auf der Festplatte an.





```{r, pipeline-list}

meta <- tar_meta(fields = c("type", "bytes", "format"), complete_only = TRUE)
setDT(meta)
meta$MB <- round(meta$bytes / 1e6, digits = 2)

# Gesamter Speicherplatzverbrauch
sum(meta$MB, na.rm = TRUE)

kable(meta[order(type, name)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```

\newpage
## Timing

### Gesamte Laufzeit

```{r, pipeline-runtime}
meta <- tar_meta(fields = c("time", "seconds"), complete_only = TRUE)
setDT(meta)
meta$mins <- round(meta$seconds / 60, digits = 2)

runtime.sum <- sum(meta$seconds)

## Sekunden
print(runtime.sum)

## Minuten
runtime.sum / 60

## Stunden
runtime.sum / 3600
```

### Laufzeit einzelner Targets

Der Zeitpunkt an dem die Targets berechnet wurden und ihre jeweilige Laufzeit in Sekunden.


```{r, pipeline-timing}
kable(meta[order(-seconds)],
      format = "latex",
      align = "r",
      booktabs = TRUE,
      longtable = TRUE) %>% kable_styling(latex_options = "repeat_header")


```



\newpage
## Warnungen



```{r, pipeling-warnings}

meta <- tar_meta(fields = "warnings", complete_only = TRUE)
setDT(meta)
meta <- meta[name != "files.network"]

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```


\newpage
## Fehlermeldungen

```{r, pipeline-errors}

meta <- tar_meta(fields = "error", complete_only = TRUE)
setDT(meta)

kable(meta,
      format = "latex",
      align = c("P{4cm}", "p{10cm}"),
      booktabs = TRUE,
      longtable = TRUE)


```









\newpage

```{r, results = "asis", echo = FALSE}
cat(readLines("CHANGELOG.md"),
    sep = "\n")

```


# Abschluss

```{r}

## Datumsstempel
print(datestamp) 

## Datum und Uhrzeit (Anfang)
print(begin.script)


## Datum und Uhrzeit (Ende)
end.script <- Sys.time()
print(end.script)


## Laufzeit des gesamten Skriptes
print(end.script - begin.script)

```


# Parameter für strenge Replikationen


```{r}
system2("openssl", "version", stdout = TRUE)

sessionInfo()

```


# Literaturverzeichnis
